# ğŸ¥ Healthcare GenAI Claims Assistant (V1)

A **Generative AIâ€“powered healthcare claims decision-support system** built using **Retrieval-Augmented Generation (RAG)** to analyze insurance policy documents and produce **evidence-grounded, auditable coverage decisions**.

ğŸ” Designed with a strong focus on **AI reliability, explainability, and quality validation** for **regulated healthcare & insurance domains**.

---

## ğŸ¯ Business Problem

Healthcare insurance claims processing requires interpreting **complex policy language** across:
- Multiple insurers  
- Exclusions & waiting periods  
- Benefit limits & sub-limits  

ğŸ“‰ Manual review is **slow, inconsistent**, and prone to **interpretation errors**.

âœ… This project demonstrates how **Generative AI + semantic retrieval** can assist claim analysis while maintaining **conservative, traceable, and auditable decision logic**.

---

## ğŸš€ Key Capabilities (V1)

### ğŸ“„ Policy Understanding
- Ingests **public healthcare insurance policy PDFs**
- Text preprocessing, normalization & **semantic chunking**

### ğŸ§  Semantic Retrieval
- **OpenAI embeddings** with batching for scalability
- **FAISS-based vector search**
- **Top-K retrieval** of relevant policy clauses per claim

### ğŸ¤– Evidence-Grounded Reasoning
- LLM reasoning **strictly constrained to retrieved evidence**
- Prevents hallucinated policy interpretations

### ğŸ“Š Structured Outputs
Each claim produces:
- **Coverage decision**
- **Conditions / exclusions**
- **Evidence sources**
- **Confidence level**

### ğŸ” Multi-Scenario Handling
- âœ… Covered  
- âš ï¸ Covered with conditions  
- âŒ Not covered / exclusions  

---

## ğŸ§¾ Example Output

```json ```
{
  "coverage_decision": "Covered with conditions",
  "conditions_or_exclusions": [
    "Waiting period applies",
    "Sub-limits applicable as per policy terms"
  ],
  "evidence_sources": [
    "ICICI Lombard.pdf"
  ],
  "confidence": "High"
}

**ğŸ—ï¸ Architecture Overview**

Policy PDFs
   â†“
Text Extraction
   â†“
Chunking
   â†“
OpenAI Embeddings (Batched)
   â†“
FAISS Vector Index
   â†“
Semantic Retrieval (Top-K)
   â†“
LLM-based Claim Reasoning
   â†“
Structured Coverage Decision + Evidence


**ğŸ§ª Synthetic claims are used to simulate real-world usage â€” no sensitive data involved.**

**ğŸ› ï¸ Tech Stack**

ğŸ Python

ğŸ”— OpenAI Embeddings & Chat Completions

ğŸ“š FAISS (Vector Database)

ğŸ§® Pandas

ğŸ“„ PyPDF2

âš™ï¸ Core RAG logic is implemented manually (no LangChain in V1) to ensure transparency, control, and debuggability.

**ğŸ” Data Governance & Compliance**

âœ… Uses only publicly available policy documents

ğŸ§ª All claims are synthetically generated

ğŸš« No real patient, provider, or claim data

ğŸ“ Built for learning, experimentation & portfolio demonstration

***ğŸ“Œ Project Status â€” Completed (V1)***

âœ”ï¸ End-to-end RAG pipeline for healthcare claim analysis
âœ”ï¸ Evidence-grounded & conservative LLM reasoning
âœ”ï¸ Insurer-aware behavior via semantic retrieval
âœ”ï¸ Robust handling of positive, conditional & negative scenarios

**ğŸ§ª QA / ML Testing Add-On (V1.1)**
**ğŸ§  AI / ML Testing & Evaluation (Planned)**

The next iteration focuses on AI Quality Assurance and ML Testing, adapting traditional QA principles to probabilistic GenAI systems.

ğŸ” Planned Testing Areas
ğŸ” Prompt Regression Testing

Compare multiple prompt variants on the same claim set

Detect coverage decision drift due to prompt changes

Ensure backward compatibility of decision logic

ğŸ“¦ Batch Evaluation with Synthetic Claims

Run large batches of synthetic claims

Analyze outcome distribution:

âœ… Covered

âš ï¸ Covered with conditions

âŒ Not covered

â“ Insufficient evidence

Identify bias, over-approval, or over-rejection trends

âš ï¸ Negative & Edge Case Testing

Missing diagnosis or insurer

Ambiguous or conflicting inputs

Non-medical / out-of-scope queries

Validate safe fallback behavior & confidence degradation

ğŸ”„ Consistency & Robustness Testing

Re-run identical claims multiple times

Validate decision stability under low-temperature settings

Detect non-deterministic or unstable responses

ğŸš¨ Hallucination & Evidence Leakage Checks

Ensure responses rely only on retrieved policy clauses

Enforce:

âŒ Not covered

â“ Insufficient evidence
when support is missing

**ğŸ§© Why This Matters**

âœ¨ This phase explicitly demonstrates:

ML testing

AI validation

GenAI quality engineering

Responsible AI practices for regulated domains
